{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNBpBNVRDcfW",
        "outputId": "2959eab9-c70e-415b-9d43-5f0e535f1bc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analysis complete.\n",
            "product_overall_sentiment_summary.csv: Overall verdict + summary\n",
            "aspect_based_opinion_per_product.csv: Aspect-wise feedback per product\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from collections import defaultdict\n",
        "\n",
        "# Download necessary NLTK datasets\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Setup Sentiment Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Step 1: Sentiment Analysis per review\n",
        "df['sentiment_score'] = df['review_description'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
        "df['sentiment_label'] = df['sentiment_score'].apply(\n",
        "    lambda x: 'Positive' if x > 0.05 else 'Negative' if x < -0.05 else 'Neutral'\n",
        ")\n",
        "\n",
        "# Step 2: Aspect-Based Sentiment per product\n",
        "product_aspect_sentiments = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    product_id = row['product_id']\n",
        "    sentiment = row['sentiment_label']\n",
        "    doc = nlp(str(row['review_description']))\n",
        "\n",
        "    for chunk in doc.noun_chunks:\n",
        "        if chunk.root.pos_ == \"NOUN\" and len(chunk.text.strip()) > 2:\n",
        "            aspect = chunk.root.lemma_.lower()\n",
        "            product_aspect_sentiments[product_id][aspect].append(sentiment)\n",
        "\n",
        "# Step 3: Summarize sentiment and aspects per product\n",
        "product_summary = []\n",
        "aspect_rows = []\n",
        "\n",
        "for product_id in df['product_id'].unique():\n",
        "    product_reviews = df[df['product_id'] == product_id]\n",
        "\n",
        "    pos = (product_reviews['sentiment_label'] == 'Positive').sum()\n",
        "    neg = (product_reviews['sentiment_label'] == 'Negative').sum()\n",
        "    neu = (product_reviews['sentiment_label'] == 'Neutral').sum()\n",
        "\n",
        "    overall_verdict = \"Liked\" if pos > neg else \"Not Liked\"\n",
        "\n",
        "    # Collect aspects\n",
        "    aspect_dict = product_aspect_sentiments[product_id]\n",
        "    appreciated = []\n",
        "    criticized = []\n",
        "\n",
        "    for aspect, sentiments in aspect_dict.items():\n",
        "        p = sentiments.count('Positive')\n",
        "        n = sentiments.count('Negative')\n",
        "        appreciated.append((aspect, p))\n",
        "        criticized.append((aspect, n))\n",
        "\n",
        "        # Save aspect-level info\n",
        "        aspect_rows.append({\n",
        "            'product_id': product_id,\n",
        "            'aspect': aspect,\n",
        "            'positive_mentions': p,\n",
        "            'negative_mentions': n,\n",
        "            'net_sentiment': p - n\n",
        "        })\n",
        "\n",
        "    appreciated.sort(key=lambda x: x[1], reverse=True)\n",
        "    criticized.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    appreciated_summary = \", \".join([asp for asp, count in appreciated if count > 0][:5])\n",
        "    criticized_summary = \", \".join([asp for asp, count in criticized if count > 0][:5])\n",
        "\n",
        "    # Final product summary\n",
        "    product_summary.append({\n",
        "        'product_id': product_id,\n",
        "        'total_reviews': len(product_reviews),\n",
        "        'positive_reviews': pos,\n",
        "        'negative_reviews': neg,\n",
        "        'neutral_reviews': neu,\n",
        "        'overall_verdict': overall_verdict,\n",
        "        'top_appreciated_aspects': appreciated_summary if appreciated_summary else \"None\",\n",
        "        'top_criticized_aspects': criticized_summary if criticized_summary else \"None\"\n",
        "    })\n",
        "\n",
        "# Convert to DataFrames\n",
        "product_sentiment_summary_df = pd.DataFrame(product_summary)\n",
        "aspect_based_opinion_df = pd.DataFrame(aspect_rows)\n",
        "\n",
        "# Save to CSVs\n",
        "product_sentiment_summary_df.to_csv(\"product_overall_sentiment_summary.csv\", index=False)\n",
        "aspect_based_opinion_df.to_csv(\"aspect_based_opinion_per_product.csv\", index=False)\n",
        "\n",
        "print(\"Analysis complete.\")\n",
        "print(\"product_overall_sentiment_summary.csv: Overall verdict + summary\")\n",
        "print(\"aspect_based_opinion_per_product.csv: Aspect-wise feedback per product\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
